# Projeto Web Mining AnalÃ­tico

Sistema de extraÃ§Ã£o, transformaÃ§Ã£o e carregamento (ETL) para anÃ¡lise de dados financeiros, desenvolvido em Python com pipeline modular e persistÃªncia em DuckDB. Inclui web scraping do InfoMoney e integraÃ§Ã£o com API YFinance para dados de criptomoedas.

## ğŸ“‹ Ãndice

- [Funcionalidades](#funcionalidades)
- [Tecnologias](#tecnologias)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [Como Executar](#como-executar)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Pipeline ETL](#pipeline-etl)
- [Exemplos de Uso](#exemplos-de-uso)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)

## ğŸš€ Funcionalidades

### Pipeline de Scraping (InfoMoney)
- **ExtraÃ§Ã£o AutomÃ¡tica**: Web scraping inteligente do InfoMoney com Selenium
- **Carregamento DinÃ¢mico**: Scroll automÃ¡tico para carregar mais notÃ­cias
- **ValidaÃ§Ã£o de Dados**: Filtragem automÃ¡tica de notÃ­cias incompletas
- **AnÃ¡lise Temporal**: ConversÃ£o de datas relativas para absolutas
- **PersistÃªncia**: Armazenamento em banco DuckDB com pandas

### Pipeline de API (YFinance)
- **ExtraÃ§Ã£o de Dados Financeiros**: IntegraÃ§Ã£o com API YFinance para criptomoedas
- **AnÃ¡lise TÃ©cnica**: CÃ¡lculo de mÃ©dias mÃ³veis (7d e 30d) e variaÃ§Ã£o percentual
- **Enriquecimento de Dados**: AdiÃ§Ã£o de indicadores tÃ©cnicos automÃ¡ticos
- **PersistÃªncia Dupla**: Armazenamento em tabelas `instruments` e `prices`

### Funcionalidades Gerais
- **Pipeline Modular**: Arquitetura ETL flexÃ­vel e extensÃ­vel
- **Interface CLI**: ExecuÃ§Ã£o via linha de comando com parÃ¢metros
- **Logging AvanÃ§ado**: Sistema de logs estruturado com diferentes nÃ­veis
- **ConfiguraÃ§Ã£o FlexÃ­vel**: Suporte a variÃ¡veis de ambiente

## ğŸ›  Tecnologias

### Core
- **Python 3.8+**
- **DuckDB**: Banco de dados analÃ­tico
- **Pandas**: ManipulaÃ§Ã£o de dados
- **NumPy**: ComputaÃ§Ã£o numÃ©rica

### Web Scraping
- **Selenium**: Web scraping e automaÃ§Ã£o
- **BeautifulSoup**: Parsing de HTML
- **WebDriver Manager**: Gerenciamento automÃ¡tico de drivers

### APIs e Dados Financeiros
- **YFinance**: API para dados financeiros
- **Requests**: Cliente HTTP

### UtilitÃ¡rios
- **Argparse**: Interface de linha de comando
- **Python-dotenv**: Gerenciamento de variÃ¡veis de ambiente
- **LXML**: Parser XML/HTML rÃ¡pido

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone <url-do-repositorio>
cd projeto_web_mining_analitico
```

### 2. Crie um ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Instale o ChromeDriver (se necessÃ¡rio)

O projeto usa o `webdriver-manager` que baixa automaticamente o ChromeDriver, mas vocÃª pode instalar manualmente:

```bash
# Ubuntu/Debian
sudo apt-get install chromium-chromedriver

# macOS
brew install chromedriver

# Windows
# Baixe do site oficial do Chrome
```

### 5. Instale dependÃªncias adicionais (opcional)

Para desenvolvimento e testes:

```bash
pip install pytest black flake8
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (Opcional)

Crie um arquivo `.env` na raiz do projeto:

```env
# Caminho do banco de dados
db_path=data/dck.db
```

## ğŸ¯ Como Executar

### ExecuÃ§Ã£o BÃ¡sica

```bash
python main.py
```

### ParÃ¢metros DisponÃ­veis

#### `--scrapping`
Executa apenas o pipeline de scraping:

```bash
python main.py --scrapping
```

#### `--api`
Executa apenas o pipeline da API (YFinance):

```bash
python main.py --api
```

#### ExecuÃ§Ã£o sem parÃ¢metros
Executa todos os pipelines disponÃ­veis:

```bash
python main.py
```

### Exemplos de Uso

```bash
# Executar apenas scraping
python main.py --scrapping

# Executar todos os pipelines
python main.py

# Ver ajuda
python main.py --help
```

## ğŸ“ Estrutura do Projeto

```
projeto_web_mining_analitico/
â”œâ”€â”€ main.py                          # Ponto de entrada principal
â”œâ”€â”€ requirements.txt                  # DependÃªncias do projeto
â”œâ”€â”€ README.md                        # Este arquivo
â”œâ”€â”€ bases/                          # Interfaces e classes base
â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â”œâ”€â”€ extractor.py            # Interface para extraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ transformers.py         # Interface para transformaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ loader.py               # Interface para carregamento
â”‚   â”‚   â””â”€â”€ pipeline.py              # Interface para pipelines
â”‚   â””â”€â”€ crawlers/
â”‚       â””â”€â”€ base_crawler.py         # Classe base para crawlers
â”œâ”€â”€ src/                            # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ settings.py             # ConfiguraÃ§Ãµes do projeto
â”‚   â”‚   â””â”€â”€ logging.py              # ConfiguraÃ§Ã£o de logs
â”‚   â”œâ”€â”€ scrapping/                  # Pipeline de scraping (InfoMoney)
â”‚   â”‚   â”œâ”€â”€ pipeline.py             # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ crawlers/
â”‚   â”‚   â”‚   â””â”€â”€ infomoney.py        # Crawler do InfoMoney
â”‚   â”‚   â””â”€â”€ tasks/
â”‚   â”‚       â”œâ”€â”€ extractor.py        # Extrator de dados
â”‚   â”‚       â”œâ”€â”€ transformer.py      # Transformador/validador
â”‚   â”‚       â””â”€â”€ loader.py           # Carregador no banco
â”‚   â””â”€â”€ api/                        # Pipeline da API (YFinance)
â”‚       â”œâ”€â”€ pipeline.py             # Pipeline YFinance
â”‚       â””â”€â”€ tasks/
â”‚           â”œâ”€â”€ extractor.py        # Extrator YFinance
â”‚           â”œâ”€â”€ transformers.py     # Transformador YFinance
â”‚           â””â”€â”€ loader.py           # Carregador YFinance
â”œâ”€â”€ data/                          # DiretÃ³rio de dados
â”‚   â””â”€â”€ dck.db                     # Banco DuckDB
â””â”€â”€ logs/                          # DiretÃ³rio de logs
    â””â”€â”€ app.log                    # Arquivo de log
```

## ğŸ”„ Pipeline ETL

### Pipeline de Scraping (InfoMoney)

#### 1. **ExtraÃ§Ã£o (Extract)**
- NavegaÃ§Ã£o automÃ¡tica no InfoMoney com Selenium
- Carregamento dinÃ¢mico de notÃ­cias (scroll automÃ¡tico)
- Parsing de HTML com BeautifulSoup
- ConversÃ£o de datas relativas para absolutas
- ExtraÃ§Ã£o de: tipo, tÃ­tulo, URL e data da notÃ­cia

#### 2. **TransformaÃ§Ã£o (Transform)**
- ValidaÃ§Ã£o de campos obrigatÃ³rios (tipo, tÃ­tulo, URL, data)
- Filtragem de notÃ­cias incompletas
- Limpeza e padronizaÃ§Ã£o de dados
- GeraÃ§Ã£o de metadados de processamento

#### 3. **Carregamento (Load)**
- PersistÃªncia em DuckDB (tabela `news`)
- InserÃ§Ã£o em lote com pandas
- GeraÃ§Ã£o automÃ¡tica de IDs sequenciais
- MÃ©todos de consulta: recentes, por tipo, totais

### Pipeline de API (YFinance)

#### 1. **ExtraÃ§Ã£o (Extract)**
- IntegraÃ§Ã£o com API YFinance
- Download de dados histÃ³ricos (6 meses)
- Suporte a diferentes sÃ­mbolos e intervalos
- Tratamento de erros de API

#### 2. **TransformaÃ§Ã£o (Transform)**
- CÃ¡lculo de variaÃ§Ã£o percentual (pct_change)
- MÃ©dias mÃ³veis de 7 e 30 dias
- Limpeza de dados nulos
- RemoÃ§Ã£o de duplicatas por data

#### 3. **Carregamento (Load)**
- PersistÃªncia em duas tabelas: `instruments` e `prices`
- Relacionamento entre instrumentos e preÃ§os
- Suporte a mÃºltiplos ativos
- Estrutura normalizada para anÃ¡lise

## ğŸ“Š Exemplos de Uso

### Executar Pipeline Completo

```bash
python main.py
```

**SaÃ­da esperada:**
```
Executando todos os pipelines...
ğŸš€ Iniciando pipeline de Scraping...
ğŸ“¡ Iniciando extraÃ§Ã£o de dados com InfoMoneyCrawler...
Loaded 150 items.
ExtraÃ­das 120 notÃ­cias com dados completos.
âœ… ExtraÃ§Ã£o concluÃ­da com sucesso (120 registros).
âš™ï¸ Iniciando transformaÃ§Ã£o de dados...
âœ… TransformaÃ§Ã£o concluÃ­da. 115 registros processados.
ğŸ’¾ Iniciando carga dos dados...
âœ… 115 notÃ­cias inseridas no banco com sucesso!
ğŸ Pipeline de Scraping finalizado em 45.23s

ğŸš€ Iniciando pipeline de ETL para YFinance...
ğŸ“¡ Iniciando extraÃ§Ã£o de dados da API YFinance...
âœ… ExtraÃ§Ã£o concluÃ­da com sucesso (180 registros).
âš™ï¸ Iniciando transformaÃ§Ã£o dos dados extraÃ­dos...
âœ… TransformaÃ§Ã£o concluÃ­da. 180 registros processados.
ğŸ’¾ Iniciando carga dos dados no banco DuckDB...
âœ… 180 registros inseridos na tabela 'prices' com sucesso.
ğŸ Pipeline YFinance finalizado em 12.45s
```

### Executar Apenas Scraping

```bash
python main.py --scrapping
```

### Consultar Dados no Banco

#### NotÃ­cias (Pipeline de Scraping)
```python
import duckdb

# Conectar ao banco
conn = duckdb.connect('data/dck.db')

# Consultar notÃ­cias recentes
result = conn.execute("""
    SELECT tipo, titulo, data_noticia 
    FROM news 
    ORDER BY data_importacao DESC 
    LIMIT 10
""").fetchall()

for row in result:
    print(f"[{row[0]}] {row[1]} - {row[2]}")
```

#### Dados Financeiros (Pipeline de API)
```python
import duckdb

# Conectar ao banco
conn = duckdb.connect('data/dck.db')

# Consultar preÃ§os recentes do Bitcoin
result = conn.execute("""
    SELECT date, close, pct_change, ma_7d, ma_30d
    FROM prices 
    WHERE symbol = 'BTC-USD'
    ORDER BY date DESC 
    LIMIT 10
""").fetchall()

for row in result:
    print(f"{row[0]}: R$ {row[1]:.2f} ({row[2]:.2%}) - MA7: {row[3]:.2f} - MA30: {row[4]:.2f}")
```

## ğŸ—„ï¸ Estrutura do Banco de Dados

### Tabela `news` (Pipeline de Scraping)

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | INTEGER | ID Ãºnico (auto-incremento) |
| `data_importacao` | TIMESTAMP | Data/hora da importaÃ§Ã£o |
| `tipo` | VARCHAR | Categoria da notÃ­cia |
| `titulo` | VARCHAR | TÃ­tulo da notÃ­cia |
| `url` | VARCHAR | URL da notÃ­cia |
| `data_noticia` | TIMESTAMP | Data da notÃ­cia |

### Tabela `instruments` (Pipeline de API)

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | INTEGER | ID Ãºnico (auto-incremento) |
| `symbol` | VARCHAR | SÃ­mbolo do ativo (ex: BTC-USD) |
| `name` | VARCHAR | Nome do ativo |
| `sector` | VARCHAR | Setor (ex: Crypto) |
| `created_at` | TIMESTAMP | Data de criaÃ§Ã£o do registro |

### Tabela `prices` (Pipeline de API)

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | INTEGER | ID Ãºnico (auto-incremento) |
| `symbol` | VARCHAR | SÃ­mbolo do ativo |
| `date` | DATE | Data do preÃ§o |
| `open` | DOUBLE | PreÃ§o de abertura |
| `high` | DOUBLE | PreÃ§o mÃ¡ximo |
| `low` | DOUBLE | PreÃ§o mÃ­nimo |
| `close` | DOUBLE | PreÃ§o de fechamento |
| `adj_close` | DOUBLE | PreÃ§o ajustado |
| `volume` | BIGINT | Volume negociado |
| `pct_change` | DOUBLE | VariaÃ§Ã£o percentual |
| `ma_7d` | DOUBLE | MÃ©dia mÃ³vel 7 dias |
| `ma_30d` | DOUBLE | MÃ©dia mÃ³vel 30 dias |

## ğŸ”§ Desenvolvimento

### Adicionando Novos Crawlers

1. Crie uma nova classe herdando de `BaseCrawler`
2. Implemente os mÃ©todos `run()` e `_parser()`
3. Adicione ao pipeline de extraÃ§Ã£o

### Adicionando Novos Transformers

1. Implemente a interface `TransformInterface`
2. Adicione lÃ³gica de validaÃ§Ã£o no mÃ©todo `is_valid()`
3. Configure no pipeline

### Adicionando Novos Loaders

1. Implemente a interface `LoadInterface`
2. Configure persistÃªncia no mÃ©todo `do_load()`
3. Adicione ao pipeline

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro de ChromeDriver

```bash
# Instalar ChromeDriver manualmente
pip install webdriver-manager
```

### Erro de DependÃªncias

```bash
# Reinstalar dependÃªncias
pip install --upgrade -r requirements.txt
```

### Erro de PermissÃ£o no Banco

```bash
# Verificar permissÃµes do diretÃ³rio data/
chmod 755 data/
```

## ğŸ“ˆ PrÃ³ximos Passos

- [x] Implementar pipeline da API (YFinance)
- [ ] Adicionar mais fontes de dados (Alpha Vantage, Yahoo Finance)
- [ ] Interface web para visualizaÃ§Ã£o
- [ ] AnÃ¡lise de sentimentos das notÃ­cias
- [ ] Dashboard em tempo real
- [ ] NotificaÃ§Ãµes automÃ¡ticas
- [ ] AnÃ¡lise de correlaÃ§Ã£o entre notÃ­cias e preÃ§os
- [ ] Machine Learning para previsÃ£o de preÃ§os

## ğŸ¤ ContribuiÃ§Ã£o

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¥ Autores

- **Joabe Levi** - *Desenvolvimento inicial* - [GitHub](https://github.com/joabe-levi)

## ğŸ“ Contato

Para dÃºvidas ou sugestÃµes, entre em contato atravÃ©s dos issues do GitHub ou por email.

---

**Desenvolvido com â¤ï¸ para anÃ¡lise de dados financeiros**
